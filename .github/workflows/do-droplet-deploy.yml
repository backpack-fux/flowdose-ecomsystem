name: Deploy to DigitalOcean Droplets

on:
  push:
    branches:
      - master
    paths:
      - 'backend/**'
      - 'storefront/**'
      - '.github/workflows/do-droplet-deploy.yml'
      - 'deploy-trigger'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        default: 'production'
        type: choice
        options:
          - production
          - staging

jobs:
  prepare_deployment:
    runs-on: ubuntu-latest
    outputs:
      backend_ip: ${{ steps.get_ips.outputs.backend_ip }}
      storefront_ip: ${{ steps.get_ips.outputs.storefront_ip }}
      can_deploy: ${{ steps.get_ips.outputs.can_deploy }}
    steps:
      - name: Checkout
        uses: actions/checkout@v3
        
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.0
        
      - name: Set Terraform Provider Credentials
        run: |
          # Instead of creating a new provider file, update the existing one
          sed -i 's/token = var.do_token/token = "${{ secrets.DO_API_TOKEN }}"/g' terraform/main.tf
        
      - name: Create Docker Compose Files
        run: |
          # Create backend compose file if it doesn't exist
          if [ ! -f "deploy/backend-compose.yml" ]; then
            cat > deploy/backend-compose.yml << 'EOL'
          version: '3.8'
          services:
            backend:
              build:
                context: ../backend
                dockerfile: Dockerfile
              environment:
                - NODE_ENV=${ENVIRONMENT}
                - DATABASE_URL=${DATABASE_URL}
                - REDIS_URL=${REDIS_URL}
                - PORT=9000
                # CORS settings
                - ADMIN_CORS=https://${ADMIN_DOMAIN},https://${STORE_DOMAIN}
                - STORE_CORS=https://${STORE_DOMAIN}
                - AUTH_CORS=https://${ADMIN_DOMAIN},https://${STORE_DOMAIN}
                # Auth secrets
                - JWT_SECRET=${JWT_SECRET}
                - COOKIE_SECRET=${COOKIE_SECRET}
                # Admin account
                - MEDUSA_ADMIN_EMAIL=${ADMIN_EMAIL}
                - MEDUSA_ADMIN_PASSWORD=${ADMIN_PASSWORD}
                # Publishable Key
                - MEDUSA_PUBLISHABLE_KEY=${PUBLISHABLE_KEY}
              restart: always
              networks:
                - flowdose-network

            caddy:
              image: caddy:2-alpine
              restart: unless-stopped
              ports:
                - "80:80"
                - "443:443"
              volumes:
                - ./Caddyfile_backend:/etc/caddy/Caddyfile
                - ../data/caddy_data:/data
                - ../data/caddy_config:/config
              depends_on:
                - backend
              networks:
                - flowdose-network

          networks:
            flowdose-network:
              external: true
          EOL
          fi
          
          # Create storefront compose file if it doesn't exist
          if [ ! -f "deploy/storefront-compose.yml" ]; then
            cat > deploy/storefront-compose.yml << 'EOL'
          version: '3.8'
          services:
            storefront:
              build:
                context: ../storefront
                dockerfile: Dockerfile
              environment:
                - NODE_ENV=${ENVIRONMENT}
                # Use HTTPS for backend URL
                - NEXT_PUBLIC_MEDUSA_BACKEND_URL=https://${ADMIN_DOMAIN}
                - NEXT_PUBLIC_MEDUSA_PUBLISHABLE_KEY=${PUBLISHABLE_KEY}
                - NEXT_PUBLIC_BASE_URL=https://${STORE_DOMAIN}
                - PORT=3000
              restart: always
              networks:
                - flowdose-network

            caddy:
              image: caddy:2-alpine
              restart: unless-stopped
              ports:
                - "80:80"
                - "443:443"
              volumes:
                - ./Caddyfile_storefront:/etc/caddy/Caddyfile
                - ../data/caddy_data:/data
                - ../data/caddy_config:/config
              depends_on:
                - storefront
              networks:
                - flowdose-network

          networks:
            flowdose-network:
              external: true
          EOL
          fi
        
      - name: Get Server IPs from Terraform Output
        id: get_ips
        working-directory: terraform
        env:
          TF_VAR_do_token: ${{ secrets.DO_API_TOKEN }}
          DO_SPACES_ACCESS_KEY: ${{ secrets.DO_SPACES_ACCESS_KEY }}
          DO_SPACES_SECRET_KEY: ${{ secrets.DO_SPACES_SECRET_KEY }}
          # Fallback IPs if Terraform state is inaccessible
          FALLBACK_BACKEND_IP: ${{ vars.BACKEND_IP || '127.0.0.1' }}
          FALLBACK_STOREFRONT_IP: ${{ vars.STOREFRONT_IP || '127.0.0.1' }}
        run: |
          # Check if secrets exist
          if [ -z "$DO_SPACES_ACCESS_KEY" ] || [ -z "$DO_SPACES_SECRET_KEY" ]; then
            echo "WARNING: DigitalOcean Spaces credentials are missing!"
            echo "Will attempt to use fallback IPs from repository variables."
            
            if [ "$FALLBACK_BACKEND_IP" = "127.0.0.1" ] || [ "$FALLBACK_STOREFRONT_IP" = "127.0.0.1" ]; then
              echo "ERROR: No fallback IPs configured. Set BACKEND_IP and STOREFRONT_IP variables in the repository."
              echo "can_deploy=false" >> $GITHUB_OUTPUT
              exit 1
            fi
            
            echo "backend_ip=$FALLBACK_BACKEND_IP" >> $GITHUB_OUTPUT
            echo "storefront_ip=$FALLBACK_STOREFRONT_IP" >> $GITHUB_OUTPUT
            echo "can_deploy=true" >> $GITHUB_OUTPUT
            
            echo "Using Fallback Backend IP: $FALLBACK_BACKEND_IP"
            echo "Using Fallback Storefront IP: $FALLBACK_STOREFRONT_IP"
            exit 0
          fi
          
          echo "Initializing Terraform with backend credentials..."
          # Check if backend_override.tf already exists and remove it
          if [ -f "backend_override.tf" ]; then
            echo "Removing existing backend_override.tf file..."
            rm backend_override.tf
          fi
          
          # Create backend override file
          cat > backend_override.tf << EOL
          terraform {
            backend "s3" {
              endpoint                    = "https://sfo3.digitaloceanspaces.com"
              bucket                      = "flowdose-state-storage"
              key                         = "flowdose/terraform.tfstate"
              region                      = "us-east-1"
              skip_credentials_validation = true
              skip_metadata_api_check     = true
              skip_region_validation      = true
              force_path_style            = false
              access_key                  = "$DO_SPACES_ACCESS_KEY"
              secret_key                  = "$DO_SPACES_SECRET_KEY"
            }
          }
          EOL
          
          # Initialize Terraform with explicit backend config
          if ! terraform init -reconfigure 2>&1 | tee terraform_init.log; then
            
            # Check if the error is about the bucket not existing (bootstrap not done)
            if grep -q "bucket does not exist" terraform_init.log; then
              echo "WARNING: Terraform state bucket does not exist. Bootstrap process not completed."
              echo "Please run the terraform-bootstrap.yml workflow first, or set up fallback IPs."
            fi
            
            echo "WARNING: Failed to initialize Terraform backend. Using fallback IPs."
            echo "backend_ip=$FALLBACK_BACKEND_IP" >> $GITHUB_OUTPUT
            echo "storefront_ip=$FALLBACK_STOREFRONT_IP" >> $GITHUB_OUTPUT
            echo "can_deploy=true" >> $GITHUB_OUTPUT
            
            echo "Using Fallback Backend IP: $FALLBACK_BACKEND_IP"
            echo "Using Fallback Storefront IP: $FALLBACK_STOREFRONT_IP"
            exit 0
          fi
          
          echo "Checking Terraform state..."
          # Try to get the output values from Terraform state directly without lock checking
          BACKEND_IP=$(terraform output -raw backend_ip 2>/dev/null | grep -o '^[0-9\.]*' || echo "")
          STOREFRONT_IP=$(terraform output -raw storefront_ip 2>/dev/null | grep -o '^[0-9\.]*' || echo "")
          
          # Check if both IPs exist
          if [ -z "$BACKEND_IP" ] || [ -z "$STOREFRONT_IP" ]; then
            echo "Infrastructure not fully provisioned yet."
            
            # Check if we have fallback IPs
            if [ "$FALLBACK_BACKEND_IP" = "127.0.0.1" ] || [ "$FALLBACK_STOREFRONT_IP" = "127.0.0.1" ]; then
              echo "No fallback IPs configured either. Deployment cannot proceed."
              echo "Please run the terraform-infrastructure.yml workflow first to provision infrastructure"
              echo "Or manually add BACKEND_IP and STOREFRONT_IP as repository variables."
              echo "can_deploy=false" >> $GITHUB_OUTPUT
              exit 1
            else
              echo "Using fallback IPs from repository variables."
              BACKEND_IP=$FALLBACK_BACKEND_IP
              STOREFRONT_IP=$FALLBACK_STOREFRONT_IP
            fi
          fi
          
          # Output these values for other jobs
          echo "backend_ip=$BACKEND_IP" >> $GITHUB_OUTPUT
          echo "storefront_ip=$STOREFRONT_IP" >> $GITHUB_OUTPUT
          echo "can_deploy=true" >> $GITHUB_OUTPUT
          
          echo "Using Backend IP: $BACKEND_IP"
          echo "Using Storefront IP: $STOREFRONT_IP"

  deploy:
    needs: prepare_deployment
    runs-on: ubuntu-latest
    if: needs.prepare_deployment.outputs.can_deploy == 'true'
    env:
      DEPLOY_ENV: ${{ github.event.inputs.environment || 'production' }}
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
    steps:
      - name: Checkout
        uses: actions/checkout@v3
        
      - name: Install SSH Key
        uses: shimataro/ssh-key-action@v2
        with:
          key: ${{ secrets.DO_SSH_PRIVATE_KEY }}
          known_hosts: 'just-a-placeholder'
          
      - name: Adding Known Hosts
        run: |
          mkdir -p ~/.ssh
          ssh-keyscan -H ${{ needs.prepare_deployment.outputs.backend_ip }} >> ~/.ssh/known_hosts
          ssh-keyscan -H ${{ needs.prepare_deployment.outputs.storefront_ip }} >> ~/.ssh/known_hosts
      
      - name: Diagnose Server Environment
        run: |
          echo "===== DIAGNOSING BACKEND SERVER ====="
          ssh -o StrictHostKeyChecking=no root@${{ needs.prepare_deployment.outputs.backend_ip }} "
            echo 'Current directory structure:'
            find /opt/flowdose -type d | sort
            
            echo -e '\nDocker status:'
            docker ps -a
            
            echo -e '\nDirectory contents:'
            ls -la /opt/flowdose/
            
            echo -e '\nChecking Dockerfile locations:'
            find /opt -name Dockerfile
            
            echo -e '\nDisplay backend-compose.yml content:'
            cat /opt/flowdose/docker-compose.yml || echo 'File not found'
            
            echo -e '\nChecking if folder is git repo:'
            cd /opt/flowdose && git status || echo 'Not a git repo'
          "
          
          echo "===== DIAGNOSING STOREFRONT SERVER ====="
          ssh -o StrictHostKeyChecking=no root@${{ needs.prepare_deployment.outputs.storefront_ip }} "
            echo 'Current directory structure:'
            find /opt/flowdose -type d | sort
            
            echo -e '\nDocker status:'
            docker ps -a
            
            echo -e '\nDirectory contents:'
            ls -la /opt/flowdose/
            
            echo -e '\nChecking Dockerfile locations:'
            find /opt -name Dockerfile
            
            echo -e '\nDisplay storefront-compose.yml content:'
            cat /opt/flowdose/docker-compose.yml || echo 'File not found'
            
            echo -e '\nChecking if folder is git repo:'
            cd /opt/flowdose && git status || echo 'Not a git repo'
          "
      
      - name: Wait for any infrastructure changes to complete
        run: sleep 60  # Give Terraform user_data scripts time to complete
      
      - name: Create Caddy config files
        run: |
          # Ensure deploy directory exists
          mkdir -p deploy
          
          # Create template files if they don't exist
          if [ ! -f "deploy/Caddyfile_backend.template" ]; then
            echo '${ADMIN_DOMAIN} {
                reverse_proxy backend:9000
                tls ${ADMIN_EMAIL_FOR_CERTS}
            }' > deploy/Caddyfile_backend.template
          fi
          
          if [ ! -f "deploy/Caddyfile_storefront.template" ]; then
            echo '${STORE_DOMAIN} {
                reverse_proxy storefront:3000
                tls ${ADMIN_EMAIL_FOR_CERTS}
            }' > deploy/Caddyfile_storefront.template
          fi
          
          # Create Caddyfile for backend from template
          cat deploy/Caddyfile_backend.template | \
            sed "s|\${ADMIN_DOMAIN}|admin.${{ secrets.DOMAIN_NAME || needs.prepare_deployment.outputs.backend_ip }}|g" | \
            sed "s|\${ADMIN_EMAIL_FOR_CERTS}|${{ secrets.ADMIN_EMAIL || 'admin@flowdose.xyz' }}|g" \
            > deploy/Caddyfile_backend
          
          # Create Caddyfile for storefront from template
          cat deploy/Caddyfile_storefront.template | \
            sed "s|\${STORE_DOMAIN}|store.${{ secrets.DOMAIN_NAME || needs.prepare_deployment.outputs.storefront_ip }}|g" | \
            sed "s|\${ADMIN_EMAIL_FOR_CERTS}|${{ secrets.ADMIN_EMAIL || 'admin@flowdose.xyz' }}|g" \
            > deploy/Caddyfile_storefront
      
      - name: Deploy Backend
        run: |
          # First copy deployment files
          scp -o StrictHostKeyChecking=no -r deploy/backend-compose.yml root@${{ needs.prepare_deployment.outputs.backend_ip }}:/opt/flowdose/docker-compose.yml
          scp -o StrictHostKeyChecking=no -r deploy/Caddyfile_backend root@${{ needs.prepare_deployment.outputs.backend_ip }}:/opt/flowdose/Caddyfile_backend
          
          # Create a repair script
          cat > repair.sh << 'EOF'
          #!/bin/bash
          set -e

          echo "=== Starting Backend Deployment Repair ==="
          cd /opt/flowdose
          
          echo "1. Fixing directory structure..."
          mkdir -p data/caddy_data data/caddy_config
          
          echo "2. Creating fresh backend directory..."
          rm -rf /opt/flowdose/backend.bak
          if [ -d "/opt/flowdose/backend" ]; then
            mv /opt/flowdose/backend /opt/flowdose/backend.bak
          fi
          mkdir -p /opt/flowdose/backend
          
          echo "3. Cloning repository to temp location..."
          rm -rf /tmp/repo-clone
          mkdir -p /tmp/repo-clone
          cd /tmp/repo-clone
          git clone https://${GH_TOKEN}@github.com/${REPO}.git .
          
          echo "4. Copying backend files with correct ownership..."
          cp -R backend/* /opt/flowdose/backend/
          chown -R root:root /opt/flowdose/backend
          
          echo "5. Fixing Dockerfile for missing files..."
          cd /opt/flowdose/backend
          if [ -f "Dockerfile" ]; then
            # Create .npmrc if it doesn't exist (referenced in original Dockerfile)
            touch .npmrc
            
            # Modify Dockerfile to handle missing files
            sed -i 's/COPY package.json .npmrc/COPY package*.json/g' Dockerfile
            
            echo "Modified Dockerfile:"
            cat Dockerfile
          else
            # Create a simple fallback Dockerfile
            echo 'FROM node:18-alpine' > Dockerfile
            echo 'WORKDIR /app' >> Dockerfile
            echo 'COPY package*.json ./' >> Dockerfile
            echo 'RUN npm install' >> Dockerfile
            echo 'COPY . .' >> Dockerfile
            echo 'RUN npm run build || true' >> Dockerfile
            echo 'EXPOSE 9000' >> Dockerfile
            echo 'CMD ["npm", "start"]' >> Dockerfile
          fi
          
          echo "6. Ensuring docker-compose.yml is properly configured..."
          cd /opt/flowdose
          sed -i 's|context: ../backend|context: ./backend|g' docker-compose.yml

          echo "=== Deployment repair complete ==="
          EOF
          
          chmod +x repair.sh
          scp -o StrictHostKeyChecking=no repair.sh root@${{ needs.prepare_deployment.outputs.backend_ip }}:/tmp/repair.sh
          
          # Execute the repair script and deploy
          ssh -o StrictHostKeyChecking=no root@${{ needs.prepare_deployment.outputs.backend_ip }} "
            export GH_TOKEN='${{ secrets.GH_TOKEN }}'
            export REPO='${{ github.repository }}'
            bash /tmp/repair.sh
            
            cd /opt/flowdose && 
            export ENVIRONMENT='${{ env.DEPLOY_ENV }}' &&
            export DATABASE_URL='${{ secrets.DATABASE_URL }}' &&
            export REDIS_URL='${{ secrets.REDIS_URL }}' &&
            export JWT_SECRET='${{ secrets.JWT_SECRET }}' &&
            export COOKIE_SECRET='${{ secrets.COOKIE_SECRET }}' &&
            export ADMIN_EMAIL='admin@flowdose.xyz' &&
            export ADMIN_PASSWORD='${{ secrets.ADMIN_PASSWORD }}' &&
            export PUBLISHABLE_KEY='${{ secrets.PUBLISHABLE_KEY }}' &&
            export ADMIN_DOMAIN='admin.${{ secrets.DOMAIN_NAME || needs.prepare_deployment.outputs.backend_ip }}' &&
            export STORE_DOMAIN='store.${{ secrets.DOMAIN_NAME || needs.prepare_deployment.outputs.storefront_ip }}' &&
            docker compose down || true &&
            docker compose build --no-cache &&
            docker compose up -d
          "
        
      - name: Deploy Storefront
        run: |
          # First copy deployment files
          scp -o StrictHostKeyChecking=no -r deploy/storefront-compose.yml root@${{ needs.prepare_deployment.outputs.storefront_ip }}:/opt/flowdose/docker-compose.yml
          scp -o StrictHostKeyChecking=no -r deploy/Caddyfile_storefront root@${{ needs.prepare_deployment.outputs.storefront_ip }}:/opt/flowdose/Caddyfile_storefront
          
          # Create a repair script
          cat > repair.sh << 'EOF'
          #!/bin/bash
          set -e

          echo "=== Starting Storefront Deployment Repair ==="
          cd /opt/flowdose
          
          echo "1. Fixing directory structure..."
          mkdir -p data/caddy_data data/caddy_config
          
          echo "2. Creating fresh storefront directory..."
          rm -rf /opt/flowdose/storefront.bak
          if [ -d "/opt/flowdose/storefront" ]; then
            mv /opt/flowdose/storefront /opt/flowdose/storefront.bak
          fi
          mkdir -p /opt/flowdose/storefront
          
          echo "3. Cloning repository to temp location..."
          rm -rf /tmp/repo-clone
          mkdir -p /tmp/repo-clone
          cd /tmp/repo-clone
          git clone https://${GH_TOKEN}@github.com/${REPO}.git .
          
          echo "4. Copying storefront files with correct ownership..."
          cp -R storefront/* /opt/flowdose/storefront/
          chown -R root:root /opt/flowdose/storefront
          
          echo "5. Fixing Dockerfile for missing files..."
          cd /opt/flowdose/storefront
          if [ -f "Dockerfile" ]; then
            # Create .npmrc if it doesn't exist (referenced in original Dockerfile)
            touch .npmrc
            
            # Modify Dockerfile to handle missing files
            sed -i 's/COPY package.json .npmrc/COPY package*.json/g' Dockerfile
            
            echo "Modified Dockerfile:"
            cat Dockerfile
          else
            # Create a simple fallback Dockerfile
            echo 'FROM node:18-alpine' > Dockerfile
            echo 'WORKDIR /app' >> Dockerfile
            echo 'COPY package*.json ./' >> Dockerfile
            echo 'RUN npm install' >> Dockerfile
            echo 'COPY . .' >> Dockerfile
            echo 'RUN npm run build || true' >> Dockerfile
            echo 'EXPOSE 3000' >> Dockerfile
            echo 'CMD ["npm", "start"]' >> Dockerfile
          fi
          
          echo "6. Ensuring docker-compose.yml is properly configured..."
          cd /opt/flowdose
          sed -i 's|context: ../storefront|context: ./storefront|g' docker-compose.yml

          echo "=== Deployment repair complete ==="
          EOF
          
          chmod +x repair.sh
          scp -o StrictHostKeyChecking=no repair.sh root@${{ needs.prepare_deployment.outputs.storefront_ip }}:/tmp/repair.sh
          
          # Execute the repair script and deploy
          ssh -o StrictHostKeyChecking=no root@${{ needs.prepare_deployment.outputs.storefront_ip }} "
            export GH_TOKEN='${{ secrets.GH_TOKEN }}'
            export REPO='${{ github.repository }}'
            bash /tmp/repair.sh
            
            cd /opt/flowdose && 
            export ENVIRONMENT='${{ env.DEPLOY_ENV }}' &&
            export PUBLISHABLE_KEY='${{ secrets.PUBLISHABLE_KEY }}' &&
            export ADMIN_DOMAIN='admin.${{ secrets.DOMAIN_NAME || needs.prepare_deployment.outputs.backend_ip }}' &&
            export STORE_DOMAIN='store.${{ secrets.DOMAIN_NAME || needs.prepare_deployment.outputs.storefront_ip }}' &&
            docker compose down || true &&
            docker compose build --no-cache &&
            docker compose up -d
          " 