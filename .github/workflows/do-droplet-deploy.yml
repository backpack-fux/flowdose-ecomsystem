name: Deploy to DigitalOcean Droplets

on:
  push:
    branches:
      - master
    paths:
      - 'backend/**'
      - 'storefront/**'
      - '.github/workflows/do-droplet-deploy.yml'
      - 'deploy-trigger'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        default: 'production'
        type: choice
        options:
          - production
          - staging

jobs:
  prepare_deployment:
    runs-on: ubuntu-latest
    outputs:
      backend_ip: ${{ steps.get_ips.outputs.backend_ip }}
      storefront_ip: ${{ steps.get_ips.outputs.storefront_ip }}
      can_deploy: ${{ steps.get_ips.outputs.can_deploy }}
    steps:
      - name: Checkout
        uses: actions/checkout@v3
        
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.0
        
      - name: Set Terraform Provider Credentials
        run: |
          cat > terraform/provider.tf << EOL
          provider "digitalocean" {
            token             = "${{ secrets.DO_API_TOKEN }}"
            spaces_access_id  = "${{ secrets.DO_SPACES_ACCESS_KEY }}"
            spaces_secret_key = "${{ secrets.DO_SPACES_SECRET_KEY }}"
          }
          EOL
        
      - name: Create Docker Compose Files
        run: |
          # Create backend compose file if it doesn't exist
          if [ ! -f "deploy/backend-compose.yml" ]; then
            cat > deploy/backend-compose.yml << 'EOL'
          version: '3.8'
          services:
            backend:
              build:
                context: ../backend
                dockerfile: Dockerfile
              environment:
                - NODE_ENV=${ENVIRONMENT}
                - DATABASE_URL=${DATABASE_URL}
                - REDIS_URL=${REDIS_URL}
                - PORT=9000
                # CORS settings
                - ADMIN_CORS=https://${ADMIN_DOMAIN},https://${STORE_DOMAIN}
                - STORE_CORS=https://${STORE_DOMAIN}
                - AUTH_CORS=https://${ADMIN_DOMAIN},https://${STORE_DOMAIN}
                # Auth secrets
                - JWT_SECRET=${JWT_SECRET}
                - COOKIE_SECRET=${COOKIE_SECRET}
                # Admin account
                - MEDUSA_ADMIN_EMAIL=${ADMIN_EMAIL}
                - MEDUSA_ADMIN_PASSWORD=${ADMIN_PASSWORD}
                # Publishable Key
                - MEDUSA_PUBLISHABLE_KEY=${PUBLISHABLE_KEY}
              restart: always
              networks:
                - flowdose-network

            caddy:
              image: caddy:2-alpine
              restart: unless-stopped
              ports:
                - "80:80"
                - "443:443"
              volumes:
                - ./Caddyfile_backend:/etc/caddy/Caddyfile
                - ../data/caddy_data:/data
                - ../data/caddy_config:/config
              depends_on:
                - backend
              networks:
                - flowdose-network

          networks:
            flowdose-network:
              external: true
          EOL
          fi
          
          # Create storefront compose file if it doesn't exist
          if [ ! -f "deploy/storefront-compose.yml" ]; then
            cat > deploy/storefront-compose.yml << 'EOL'
          version: '3.8'
          services:
            storefront:
              build:
                context: ../storefront
                dockerfile: Dockerfile
              environment:
                - NODE_ENV=${ENVIRONMENT}
                # Use HTTPS for backend URL
                - NEXT_PUBLIC_MEDUSA_BACKEND_URL=https://${ADMIN_DOMAIN}
                - NEXT_PUBLIC_MEDUSA_PUBLISHABLE_KEY=${PUBLISHABLE_KEY}
                - NEXT_PUBLIC_BASE_URL=https://${STORE_DOMAIN}
                - PORT=3000
              restart: always
              networks:
                - flowdose-network

            caddy:
              image: caddy:2-alpine
              restart: unless-stopped
              ports:
                - "80:80"
                - "443:443"
              volumes:
                - ./Caddyfile_storefront:/etc/caddy/Caddyfile
                - ../data/caddy_data:/data
                - ../data/caddy_config:/config
              depends_on:
                - storefront
              networks:
                - flowdose-network

          networks:
            flowdose-network:
              external: true
          EOL
          fi
        
      - name: Get Server IPs from Terraform Output
        id: get_ips
        working-directory: terraform
        env:
          TF_VAR_do_token: ${{ secrets.DO_API_TOKEN }}
          DO_SPACES_ACCESS_KEY: ${{ secrets.DO_SPACES_ACCESS_KEY }}
          DO_SPACES_SECRET_KEY: ${{ secrets.DO_SPACES_SECRET_KEY }}
          # Fallback IPs if Terraform state is inaccessible
          FALLBACK_BACKEND_IP: ${{ vars.BACKEND_IP || '127.0.0.1' }}
          FALLBACK_STOREFRONT_IP: ${{ vars.STOREFRONT_IP || '127.0.0.1' }}
        run: |
          # Check if secrets exist
          if [ -z "$DO_SPACES_ACCESS_KEY" ] || [ -z "$DO_SPACES_SECRET_KEY" ]; then
            echo "WARNING: DigitalOcean Spaces credentials are missing!"
            echo "Will attempt to use fallback IPs from repository variables."
            
            if [ "$FALLBACK_BACKEND_IP" = "127.0.0.1" ] || [ "$FALLBACK_STOREFRONT_IP" = "127.0.0.1" ]; then
              echo "ERROR: No fallback IPs configured. Set BACKEND_IP and STOREFRONT_IP variables in the repository."
              echo "can_deploy=false" >> $GITHUB_OUTPUT
              exit 1
            fi
            
            echo "backend_ip=$FALLBACK_BACKEND_IP" >> $GITHUB_OUTPUT
            echo "storefront_ip=$FALLBACK_STOREFRONT_IP" >> $GITHUB_OUTPUT
            echo "can_deploy=true" >> $GITHUB_OUTPUT
            
            echo "Using Fallback Backend IP: $FALLBACK_BACKEND_IP"
            echo "Using Fallback Storefront IP: $FALLBACK_STOREFRONT_IP"
            exit 0
          fi
          
          echo "Initializing Terraform with backend credentials..."
          # Create backend override file
          cat > backend_override.tf << EOL
          terraform {
            backend "s3" {
              endpoint                    = "https://sfo3.digitaloceanspaces.com"
              bucket                      = "flowdose-state-storage"
              key                         = "flowdose/terraform.tfstate"
              region                      = "us-east-1"
              skip_credentials_validation = true
              skip_metadata_api_check     = true
              skip_region_validation      = true
              force_path_style            = false
              access_key                  = "$DO_SPACES_ACCESS_KEY"
              secret_key                  = "$DO_SPACES_SECRET_KEY"
            }
          }
          EOL
          
          # Initialize Terraform with explicit backend config
          if ! terraform init -reconfigure 2>&1 | tee terraform_init.log; then
            
            # Check if the error is about the bucket not existing (bootstrap not done)
            if grep -q "bucket does not exist" terraform_init.log; then
              echo "WARNING: Terraform state bucket does not exist. Bootstrap process not completed."
              echo "Please run the terraform-bootstrap.yml workflow first, or set up fallback IPs."
            fi
            
            echo "WARNING: Failed to initialize Terraform backend. Using fallback IPs."
            echo "backend_ip=$FALLBACK_BACKEND_IP" >> $GITHUB_OUTPUT
            echo "storefront_ip=$FALLBACK_STOREFRONT_IP" >> $GITHUB_OUTPUT
            echo "can_deploy=true" >> $GITHUB_OUTPUT
            
            echo "Using Fallback Backend IP: $FALLBACK_BACKEND_IP"
            echo "Using Fallback Storefront IP: $FALLBACK_STOREFRONT_IP"
            exit 0
          fi
          
          echo "Checking Terraform state..."
          # Check if Terraform is currently executing (if a lock exists)
          if terraform force-unlock -force $(terraform state pull | jq -r '.serial') 2>/dev/null; then
            echo "Terraform state is locked. Skipping deployment."
            echo "can_deploy=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Try to get the output values from Terraform state
          BACKEND_IP=$(terraform output -raw backend_ip 2>/dev/null)
          STOREFRONT_IP=$(terraform output -raw storefront_ip 2>/dev/null)
          
          # Check if both IPs exist
          if [ -z "$BACKEND_IP" ] || [ -z "$STOREFRONT_IP" ]; then
            echo "Infrastructure not fully provisioned yet. Using fallback IPs."
            BACKEND_IP=$FALLBACK_BACKEND_IP
            STOREFRONT_IP=$FALLBACK_STOREFRONT_IP
          fi
          
          # Output these values for other jobs
          echo "backend_ip=$BACKEND_IP" >> $GITHUB_OUTPUT
          echo "storefront_ip=$STOREFRONT_IP" >> $GITHUB_OUTPUT
          echo "can_deploy=true" >> $GITHUB_OUTPUT
          
          echo "Using Backend IP: $BACKEND_IP"
          echo "Using Storefront IP: $STOREFRONT_IP"

  deploy:
    needs: prepare_deployment
    runs-on: ubuntu-latest
    if: needs.prepare_deployment.outputs.can_deploy == 'true'
    env:
      DEPLOY_ENV: ${{ github.event.inputs.environment || 'production' }}
    steps:
      - name: Checkout
        uses: actions/checkout@v3
        
      - name: Install SSH Key
        uses: shimataro/ssh-key-action@v2
        with:
          key: ${{ secrets.DO_SSH_PRIVATE_KEY }}
          known_hosts: 'just-a-placeholder'
          
      - name: Adding Known Hosts
        run: |
          mkdir -p ~/.ssh
          ssh-keyscan -H ${{ needs.prepare_deployment.outputs.backend_ip }} >> ~/.ssh/known_hosts
          ssh-keyscan -H ${{ needs.prepare_deployment.outputs.storefront_ip }} >> ~/.ssh/known_hosts
      
      - name: Wait for any infrastructure changes to complete
        run: sleep 60  # Give Terraform user_data scripts time to complete
      
      - name: Create Caddy config files
        run: |
          # Ensure deploy directory exists
          mkdir -p deploy
          
          # Create template files if they don't exist
          if [ ! -f "deploy/Caddyfile_backend.template" ]; then
            echo '${ADMIN_DOMAIN} {
                reverse_proxy backend:9000
                tls ${ADMIN_EMAIL_FOR_CERTS}
            }' > deploy/Caddyfile_backend.template
          fi
          
          if [ ! -f "deploy/Caddyfile_storefront.template" ]; then
            echo '${STORE_DOMAIN} {
                reverse_proxy storefront:3000
                tls ${ADMIN_EMAIL_FOR_CERTS}
            }' > deploy/Caddyfile_storefront.template
          fi
          
          # Create Caddyfile for backend from template
          cat deploy/Caddyfile_backend.template | \
            sed "s|\${ADMIN_DOMAIN}|admin.${{ secrets.DOMAIN_NAME || needs.prepare_deployment.outputs.backend_ip }}|g" | \
            sed "s|\${ADMIN_EMAIL_FOR_CERTS}|${{ secrets.ADMIN_EMAIL || 'admin@flowdose.xyz' }}|g" \
            > deploy/Caddyfile_backend
          
          # Create Caddyfile for storefront from template
          cat deploy/Caddyfile_storefront.template | \
            sed "s|\${STORE_DOMAIN}|store.${{ secrets.DOMAIN_NAME || needs.prepare_deployment.outputs.storefront_ip }}|g" | \
            sed "s|\${ADMIN_EMAIL_FOR_CERTS}|${{ secrets.ADMIN_EMAIL || 'admin@flowdose.xyz' }}|g" \
            > deploy/Caddyfile_storefront
      
      - name: Deploy Backend
        run: |
          # First copy deployment files
          scp -o StrictHostKeyChecking=no -r deploy/backend-compose.yml root@${{ needs.prepare_deployment.outputs.backend_ip }}:/opt/flowdose/docker-compose.yml
          scp -o StrictHostKeyChecking=no -r deploy/Caddyfile_backend root@${{ needs.prepare_deployment.outputs.backend_ip }}:/opt/flowdose/Caddyfile_backend
          
          # Now deploy with environment variables
          ssh -o StrictHostKeyChecking=no root@${{ needs.prepare_deployment.outputs.backend_ip }} "
            cd /opt/flowdose && 
            git pull &&
            export ENVIRONMENT='${{ env.DEPLOY_ENV }}' &&
            export DATABASE_URL='${{ secrets.DATABASE_URL }}' &&
            export REDIS_URL='${{ secrets.REDIS_URL }}' &&
            export JWT_SECRET='${{ secrets.JWT_SECRET }}' &&
            export COOKIE_SECRET='${{ secrets.COOKIE_SECRET }}' &&
            export ADMIN_EMAIL='admin@flowdose.xyz' &&
            export ADMIN_PASSWORD='${{ secrets.ADMIN_PASSWORD }}' &&
            export PUBLISHABLE_KEY='${{ secrets.PUBLISHABLE_KEY }}' &&
            export ADMIN_DOMAIN='admin.${{ secrets.DOMAIN_NAME || needs.prepare_deployment.outputs.backend_ip }}' &&
            export STORE_DOMAIN='store.${{ secrets.DOMAIN_NAME || needs.prepare_deployment.outputs.storefront_ip }}' &&
            docker compose down &&
            docker compose build --no-cache &&
            docker compose up -d
          "
        
      - name: Deploy Storefront
        run: |
          # First copy deployment files
          scp -o StrictHostKeyChecking=no -r deploy/storefront-compose.yml root@${{ needs.prepare_deployment.outputs.storefront_ip }}:/opt/flowdose/docker-compose.yml
          scp -o StrictHostKeyChecking=no -r deploy/Caddyfile_storefront root@${{ needs.prepare_deployment.outputs.storefront_ip }}:/opt/flowdose/Caddyfile_storefront
          
          # Now deploy with environment variables
          ssh -o StrictHostKeyChecking=no root@${{ needs.prepare_deployment.outputs.storefront_ip }} "
            cd /opt/flowdose && 
            git pull &&
            export ENVIRONMENT='${{ env.DEPLOY_ENV }}' &&
            export PUBLISHABLE_KEY='${{ secrets.PUBLISHABLE_KEY }}' &&
            export ADMIN_DOMAIN='admin.${{ secrets.DOMAIN_NAME || needs.prepare_deployment.outputs.backend_ip }}' &&
            export STORE_DOMAIN='store.${{ secrets.DOMAIN_NAME || needs.prepare_deployment.outputs.storefront_ip }}' &&
            docker compose down &&
            docker compose build --no-cache &&
            docker compose up -d
          " 